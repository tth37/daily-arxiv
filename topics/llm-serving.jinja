{% extends "base.jinja" %}

{% set query = '((ti:"large language model" OR abs:"large language model" OR ti:LLM OR abs:LLM) AND (ti:inference OR abs:inference OR ti:serving OR abs:serving OR ti:deployment OR abs:deployment OR ti:acceleration OR abs:acceleration OR ti:latency OR abs:latency OR ti:throughput OR abs:throughput OR ti:scalable OR abs:scalable OR ti:distributed OR abs:distributed OR ti:quantization OR abs:quantization OR ti:distillation OR abs:distillation OR ti:optimization OR abs:optimization OR ti:parallelization OR abs:parallelization OR ti:system OR abs:system OR ti:systems OR abs:systems))' %}
{% set description = 'Research on LLM serving, inference, and deployment systems focuses on optimizing the performance, scalability, and efficiency of large-scale language models for real-world applications, addressing challenges in latency, resource utilization, scalability, and integration.' %}
{% set name = 'LLM Serving' %}
{% set max_papers = 30 %}
{% set max_selected_papers = 5 %}

{{ super() }}
